{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da38b36f",
   "metadata": {},
   "source": [
    "Que 1 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09779e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "\n",
    "!pip install requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "headers = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "\n",
    "headers\n",
    "\n",
    "header_names = []\n",
    "\n",
    "for i in headers:\n",
    "    header_names.append(i.text.strip())\n",
    "    \n",
    "header_names\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Wikipedia_header = pd.DataFrame({})\n",
    "\n",
    "Wikipedia_header['Wikipedia Headers'] = header_names\n",
    "\n",
    "Wikipedia_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197f7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0a94337",
   "metadata": {},
   "source": [
    "Que 2 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.imdb.com/chart/top/\")\n",
    "\n",
    "page\n",
    "\n",
    "page.content\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "name=soup.find_all('td',class_='titleColumn')\n",
    "\n",
    "Movie_Title=[]\n",
    "\n",
    "for i in name:\n",
    "    Movie_Title.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Movie_Title\n",
    "\n",
    "rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "Movie_Rating=[]\n",
    "\n",
    "for i in rating:\n",
    " Movie_Rating.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Movie_Rating\n",
    "\n",
    "year=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "\n",
    "Year_of_Release=[]\n",
    "\n",
    "for i in year:\n",
    " Year_of_Release.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Year_of_Release\n",
    "\n",
    "#store scrapped data in dataframe\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Movie Title']= Movie_Title[:101]\n",
    "data['Rating']=Movie_Rating[:101]\n",
    "data['Year_of_Release']=Year_of_Release[:101]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d5a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51836648",
   "metadata": {},
   "source": [
    "Que 3 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Page=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "\n",
    "Page\n",
    "\n",
    "Page.content\n",
    "\n",
    "soup=BeautifulSoup(Page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "#finding movie names\n",
    "\n",
    "Name=soup.find_all('td',class_=\"titleColumn\")\n",
    "\n",
    "Movie_Name=[]\n",
    "\n",
    "for i in Name:\n",
    " Movie_Name.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Movie_Name\n",
    "\n",
    "#finding movie ratings\n",
    "\n",
    "rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "Rating=[]\n",
    "\n",
    "for i in rating:\n",
    " Rating.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Rating\n",
    "\n",
    "#finding year of release\n",
    "\n",
    "year=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "\n",
    "Year_of_Release=[]\n",
    "\n",
    "for i in year:\n",
    " Year_of_Release.append(i.text.replace('\\n',' '))\n",
    "\n",
    "Year_of_Release\n",
    "\n",
    "#storing data in DataFrame\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "data['Movie Name']=Movie_Name[:101]\n",
    "\n",
    "data['Rating']=Rating[:101]\n",
    "\n",
    "data['Year of Release']=Year_of_Release[:101]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cff08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c5bbfc",
   "metadata": {},
   "source": [
    "Que 4 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=requests.get('https://meesho.com/bags-ladies/pl/p7vbp')\n",
    "\n",
    "new\n",
    "\n",
    "new.content\n",
    "\n",
    "soup=BeautifulSoup(new.content)\n",
    "\n",
    "soup\n",
    "\n",
    "product_name=soup.find_all('p',class_ = \"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\")\n",
    "\n",
    "Product_name=[]\n",
    "for i in product_name:\n",
    " Product_name.append(i.text)\n",
    "\n",
    "Product_name\n",
    "\n",
    "#price of poduct\n",
    "product_price=soup.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\")\n",
    "\n",
    "Product_price=[]\n",
    "\n",
    "for i in product_price:\n",
    " Product_price.append(i.text)\n",
    "\n",
    "Product_price\n",
    "\n",
    "#discount on products\n",
    "\n",
    "product_discount=soup.find_all('span',class_=\"Text__StyledText-sc-oo0kvp-0 lnonyH\")\n",
    "\n",
    "Product_discount=[]\n",
    "\n",
    "for i in product_discount:\n",
    " Product_discount.append(i.text)\n",
    "\n",
    "Product_discount\n",
    "\n",
    "#loading the data in DataFrame\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "df['Product_name']=Product_name\n",
    "\n",
    "df['Product_price']=Product_price\n",
    "\n",
    "df['Product_discount']=Product_discount\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333ce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d3b01ea",
   "metadata": {},
   "source": [
    "Que 5 (a) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "def Top_Mens_Teams(url):\n",
    " page = requests.get(url)\n",
    " page.content\n",
    " soup = BeautifulSoup(page.content)\n",
    " soup\n",
    " table = soup.find(\"tbody\")\n",
    "\n",
    "#find teams\n",
    " team_name = table.find_all(\"span\",class_=\"u-hide-phablet\")[0:10]\n",
    " teams = []\n",
    " for i in team_name:\n",
    "        teams.append(i.text)\n",
    "#find matches\n",
    " match = table.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    " f_match = table.find(\"td\",class_=\"rankings-block__banner--matches\").text\n",
    " f_points = table.find(\"td\",class_=\"rankings-block__banner--points\").text\n",
    " matches = [f_match,f_points]\n",
    " for i in match:\n",
    "        matches.append(i.text)\n",
    " m_records = matches[0:20:2]\n",
    " m_points = matches[1:20:2]\n",
    "\n",
    "\n",
    "#ratings\n",
    " f_rating = table.find(\"td\",class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n','').strip()\n",
    " ratings = table.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")[0:10]\n",
    " team_rating = [f_rating]\n",
    " for i in ratings:\n",
    "    team_rating.append(i.text)\n",
    "\n",
    " data = list(zip(teams,m_records,m_points,team_rating))\n",
    " import pandas as pd\n",
    " df = pd.DataFrame(data, columns = [\"Team Name\",\"Matches\",\"Points\",\"Ratings\"])\n",
    " return(df)\n",
    "\n",
    "Top_Mens_Teams(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fda901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1202704d",
   "metadata": {},
   "source": [
    "Que 5 (b) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b237bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "\n",
    "def Top_Batsmen(url):\n",
    " page = requests.get(url)\n",
    " page.content\n",
    " soup = BeautifulSoup(page.content)\n",
    " table = soup.find(\"table\",class_=\"table rankings-table\")\n",
    " first_player = table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " first_team = table.find(\"div\",class_=\"rankings-block__banner--nationality\").text.replace('\\n','')\n",
    " first_rating = table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    "#players\n",
    " players = table.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    " player=[first_player]\n",
    " for i in players:\n",
    "        player.append(i.text.replace('\\n',' '))\n",
    "\n",
    "        \n",
    "#teams\n",
    " teams= table.find_all(\"span\",class_=\"table-body__logo-text\")[0:9]\n",
    " team = [first_team]\n",
    " for i in teams:\n",
    "        team.append(i.text)\n",
    "        \n",
    "        \n",
    "#Rating\n",
    " ratings = table.find_all(\"td\",class_=\"table-body__cell rating\")[0:9]\n",
    " rating = [first_rating]\n",
    " for i in ratings:\n",
    "        rating.append(i.text)\n",
    "\n",
    "        \n",
    "        \n",
    " data = list(zip(player,team,rating))\n",
    " import pandas as pd\n",
    " df = pd.DataFrame(data, columns = [\"Player Name\",\"Team\",\"Rating\"])\n",
    " return(df)\n",
    "\n",
    "Top_Batsmen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa86ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48bb53b1",
   "metadata": {},
   "source": [
    "Que 5 (c) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "def Top_Bowler(url):\n",
    " page=requests.get(url)\n",
    " page.content\n",
    " soup=BeautifulSoup(page.content)\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    "\n",
    "\n",
    "#first_Bowler\n",
    " first_bowler=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " first_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    " first_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    "\n",
    "\n",
    "#Bowler\n",
    " bowlers=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")[0:10]\n",
    " Bowler=[first_bowler]\n",
    " for i in bowlers:\n",
    "        Bowler.append(i.text.replace('\\n',' '))\n",
    " \n",
    "\n",
    "#teams\n",
    " teams=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " Team=[first_team]\n",
    " for i in teams:\n",
    "        Team.append(i.text.replace('\\n',' '))\n",
    "\n",
    "#rating\n",
    " rating=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " Rating=[first_rating]\n",
    " for i in rating:\n",
    "        Rating.append(i.text)\n",
    "\n",
    "        \n",
    " data=list(zip(Bowler,Team,Rating))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['Bowler','Team','Rating'])\n",
    " return(df)\n",
    "\n",
    "Top_Bowler(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06159e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9446869",
   "metadata": {},
   "source": [
    "Que 6 (a) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "\n",
    "def Top_womens_teams(url):\n",
    " page=requests.get(url)\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('tbody')\n",
    "\n",
    " team=table.find_all('span',class_=\"u-hide-phablet\")[0:10]\n",
    " teams=[]\n",
    " for i in team:\n",
    "        teams.append(i.text)\n",
    "\n",
    "\n",
    " match1=table.find('td',class_=\"rankings-block__banner--matches\").text\n",
    " point1=table.find('td',class_=\"rankings-block__banner--points\").text\n",
    " matches=table.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "\n",
    " Number_of_matches=[match1,point1]\n",
    " for i in matches:\n",
    "    Number_of_matches.append(i.text)\n",
    "\n",
    " m_record=Number_of_matches[0:20:2]\n",
    " m_points=Number_of_matches[1:20:2]\n",
    "\n",
    "    \n",
    "    \n",
    "#rating\n",
    " f_rating=table.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n',' ')\n",
    " rating=table.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    " Ratings=[f_rating]\n",
    " for i in rating:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    " data=list(zip(teams,m_record,m_points,Ratings))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['Team Name','Matches','Points','Ratings'])\n",
    " return(df)\n",
    "\n",
    "\n",
    "Top_womens_teams(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8da42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ee9579",
   "metadata": {},
   "source": [
    "Que 6 (b) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baec45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "\n",
    "def Top_womens_batsmen(url):\n",
    " page=requests.get(url)\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    " fw_player=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " fw_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    " fw_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    " w_batsmen=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    " women_batsmen=[fw_player]\n",
    " for i in w_batsmen:\n",
    "    women_batsmen.append(i.text.replace('\\n',' '))\n",
    "\n",
    "\n",
    " w_teams=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " women_team=[fw_team]\n",
    " for i in w_teams:\n",
    "    women_team.append(i.text)\n",
    "\n",
    "\n",
    " w_ratings=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " Player_rating=[fw_rating]\n",
    " for i in w_ratings:\n",
    "    Player_rating.append(i.text)\n",
    "\n",
    "\n",
    " data=list(zip(women_batsmen,women_team,Player_rating))\n",
    "\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=[\"women_batsmen\",\"Team\",\"Player_rating\"])\n",
    " return(df)\n",
    "\n",
    "Top_womens_batsmen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5525515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a53bc32",
   "metadata": {},
   "source": [
    "Que 6 (c) - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183848ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "def Women_allrounder(url):\n",
    " page=requests.get(url)\n",
    " page.content\n",
    " soup=BeautifulSoup(page.content)\n",
    "\n",
    " table=soup.find('table',class_=\"table rankings-table\")\n",
    " f_allrounder=table.find('div',class_=\"rankings-block__banner--name-large\").text\n",
    " f_allrounder_team=table.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n',' ')\n",
    " f_allrounder_rating=table.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "\n",
    "\n",
    "#allrounders\n",
    " all_rounders=table.find_all('td',class_=\"table-body__cell rankings-table__name name\")[0:10]\n",
    " W_allrounders=[f_allrounder]\n",
    " for i in all_rounders:\n",
    "    W_allrounders.append(i.text.replace('\\n',' '))\n",
    "\n",
    "#allrounder teams\n",
    " all_rounder_team=table.find_all('span',class_=\"table-body__logo-text\")[0:10]\n",
    " w_allrounder_team=[f_allrounder_team]\n",
    " for i in all_rounder_team:\n",
    "        w_allrounder_team.append(i.text.replace('\\n',' '))\n",
    "\n",
    "\n",
    "#allrounder ratings\n",
    " all_rounder_rating=table.find_all('td',class_=\"table-body__cell rating\")[0:10]\n",
    " w_allrounder_rating=[f_allrounder_rating]\n",
    " for i in all_rounder_rating:\n",
    "        w_allrounder_rating.append(i.text)\n",
    "\n",
    " data=list(zip(W_allrounders,w_allrounder_team,w_allrounder_rating))\n",
    " import pandas as pd\n",
    " df=pd.DataFrame(data,columns=['W_allrounders','w_allrounder_team','w_allrounder_rating'])\n",
    " return(df)\n",
    "\n",
    "Women_allrounder(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2a7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fc852e9",
   "metadata": {},
   "source": [
    "Que 7 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://coreyms.com/\"\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "\n",
    "articles = soup.find_all('article')\n",
    "\n",
    "data = []\n",
    "for article in articles:\n",
    "    header = article.find(\"header\")\n",
    "    \n",
    "#title\n",
    "    title = header.find(\"h2\").text\n",
    "\n",
    "    \n",
    "#date\n",
    "    date = header.find(\"time\", class_=\"entry-time\").text\n",
    "    div_block = article.find(\"div\", class_=\"entry-content\")\n",
    "\n",
    "    \n",
    "#paragraph\n",
    "    paragraph_content = div_block.find(\"p\").text\n",
    "    try:\n",
    "        youtube_link = div_block.find(\"iframe\", class_=\"youtube-player\")['src']\n",
    "        video_code = youtube_link.split(\"?\")[0].split(\"/\")[-1]\n",
    "    except:\n",
    "        video_code = \"NA\"\n",
    "    \n",
    "\n",
    "#video Code\n",
    "    data.append([title,date, paragraph_content, video_code])\n",
    "    \n",
    "#creating the dataframe\n",
    "columns = [\"Title\",\"Date\", \"Content\",\"Video Code\"]\n",
    "data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc0c191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e09c25b",
   "metadata": {},
   "source": [
    "Que 8 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "page10 = requests.get(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\")\n",
    "\n",
    "page10\n",
    "\n",
    "page10.content\n",
    "\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "soup10\n",
    "\n",
    "#Exracting house title\n",
    "h_title = soup10.find_all('h2', class_=\"heading-6 flex items-center font-semi-bold m-0\")\n",
    "\n",
    "h_title\n",
    "\n",
    "house_title = []\n",
    "\n",
    "for ht in h_title:\n",
    "    house_title.append(ht.text)\n",
    "    \n",
    "house_title\n",
    "\n",
    "len (house_title)\n",
    "\n",
    "\n",
    "#Extracting location\n",
    "loc = soup10.find_all('div', class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\")\n",
    "\n",
    "loc\n",
    "\n",
    "location = []\n",
    "\n",
    "for lc in loc:\n",
    "    location.append(lc.text)\n",
    "    \n",
    "location\n",
    "\n",
    "len (location)\n",
    "\n",
    "\n",
    "#Extracting cost of the house\n",
    "cost = soup10.find_all('div', class_=\"font-semi-bold heading-6\")\n",
    "\n",
    "cost\n",
    "\n",
    "\n",
    "price = []\n",
    "\n",
    "for p in cost:\n",
    "    price.append(p.text)\n",
    "    \n",
    "price\n",
    "\n",
    "f_price = []\n",
    "area = []\n",
    "\n",
    "for pr in range(0,len(price)):\n",
    "    \n",
    "    if pr%3:\n",
    "        f_price.append(price[pr])\n",
    "    else:\n",
    "        area.append(price[pr])\n",
    "        \n",
    "        \n",
    "#Printing build up area of the house\n",
    "area\n",
    "\n",
    "\n",
    "\n",
    "#Printing Prices and emi of the house\n",
    "f_price\n",
    "\n",
    "\n",
    "#Seperating EMI and price of the houses\n",
    "\n",
    "total_price = []\n",
    "emi = []\n",
    "for pt in range(0, len(f_price)):\n",
    "    if pt%2:\n",
    "        total_price.append(f_price[pt])\n",
    "    else:\n",
    "        emi.append(f_price[pt])\n",
    "        \n",
    "#Printing total price of the house\n",
    "total_price\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Printing EMIs of the house\n",
    "emi\n",
    "\n",
    "\n",
    "\n",
    "print(len(house_title), len(location), len(area), len(total_price), len(emi))\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "House_details = pd.DataFrame({})\n",
    "\n",
    "House_details['House Title'] = house_title\n",
    "House_details['Location'] = location\n",
    "House_details['Area'] = area\n",
    "House_details['Monthly EMI'] = emi\n",
    "House_details['Total Price'] = total_price\n",
    "\n",
    "\n",
    "House_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93032bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5527e8f3",
   "metadata": {},
   "source": [
    "Que 9 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be145829",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
    "\n",
    "page=requests.get(url)\n",
    "\n",
    "page.content\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "Restaurant_Name=[]\n",
    "Price_and_Cuisine=[]\n",
    "Location=[]\n",
    "Ratings=[]\n",
    "Image_Url=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    " Restaurant_Name.append(i.text)\n",
    "Restaurant_Name\n",
    "\n",
    "\n",
    "Price_and_Cuisine=[]\n",
    "for i in soup.find_all('div',class_=\"detail-info\"):\n",
    " Price_and_Cuisine.append(i.text.replace('₹',' '))\n",
    "Price_and_Cuisine\n",
    "\n",
    "\n",
    "Location=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    " Location.append(i.text)\n",
    "Location\n",
    "\n",
    "\n",
    "Ratings=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    " Ratings.append(i.text)\n",
    "Ratings\n",
    "\n",
    "\n",
    "Image_Url=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    " Image_Url.append(i['data-src'])\n",
    "Image_Url\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame()\n",
    "data['Restaurant_Name']=Restaurant_Name\n",
    "data['Price_and_Cuisine']=Price_and_Cuisine\n",
    "data['Location']=Location\n",
    "data['Ratings']=Ratings\n",
    "data['Image_Url']=Image_Url\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb5e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24e772bc",
   "metadata": {},
   "source": [
    "Que 10 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ae7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.bewakoof.com/women-tshirts?ga_q=tshirts\"\n",
    "\n",
    "page=requests.get(url)\n",
    "page.content\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "Product_Name=[]\n",
    "Price=[]\n",
    "Image_Url=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('div',class_=\"productCardDetail\"):\n",
    " Product_Name.append(i.text)\n",
    "Product_Name\n",
    "\n",
    "\n",
    "Price=[]\n",
    "for i in soup.find_all('span',class_=\"discountedPriceText\"):\n",
    " Price.append(i.text)\n",
    "Price\n",
    "\n",
    "\n",
    "Image_Url=[]\n",
    "for i in soup.find_all('img',class_=\"productImgTag\"):\n",
    " Image_Url.append(i['src'])\n",
    "Image_Url\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Product_Name']=Product_Name\n",
    "df['Price']=Price\n",
    "df['Image_Url']=Image_Url\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb864f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b2284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e04ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52af41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920c0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092a36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
